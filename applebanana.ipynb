{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599533168668",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 153 samples, validate on 66 samples\nEpoch 1/20\n153/153 [==============================] - 10s 65ms/step - loss: 0.9135 - acc: 0.7778 - val_loss: 1.6244 - val_acc: 0.0606\nEpoch 2/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.3588 - acc: 0.8497 - val_loss: 1.5450 - val_acc: 0.1970\nEpoch 3/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.2904 - acc: 0.8824 - val_loss: 1.0746 - val_acc: 0.3333\nEpoch 4/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.1802 - acc: 0.9412 - val_loss: 0.1272 - val_acc: 0.9848\nEpoch 5/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.2259 - acc: 0.9150 - val_loss: 0.5346 - val_acc: 0.6667\nEpoch 6/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.1023 - acc: 0.9739 - val_loss: 0.4014 - val_acc: 0.8333\nEpoch 7/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0945 - acc: 0.9673 - val_loss: 0.1970 - val_acc: 0.9545\nEpoch 8/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0621 - acc: 0.9739 - val_loss: 0.4297 - val_acc: 0.7727\nEpoch 9/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 1.0000\nEpoch 10/20\n153/153 [==============================] - 2s 16ms/step - loss: 0.0448 - acc: 0.9869 - val_loss: 0.3129 - val_acc: 0.8636\nEpoch 11/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0413 - acc: 0.9869 - val_loss: 0.2896 - val_acc: 0.8939\nEpoch 12/20\n153/153 [==============================] - 2s 16ms/step - loss: 0.0359 - acc: 0.9935 - val_loss: 0.2443 - val_acc: 0.9394\nEpoch 13/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 1.0000\nEpoch 14/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.2100 - val_acc: 0.9394\nEpoch 15/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9697\nEpoch 16/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 1.1772 - val_acc: 0.4545\nEpoch 17/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0162 - acc: 0.9935 - val_loss: 0.2235 - val_acc: 0.9242\nEpoch 18/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000\nEpoch 19/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 1.0000\nEpoch 20/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1529 - val_acc: 0.9394\n"
    }
   ],
   "source": [
    "folder = [\"apple\", \"banana\"]\n",
    "\n",
    "# 画像とラベルを格納するための配列を準備\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "#ファイルオープン～が配列生成までを関数化\n",
    "#画像サイズは50x50に強制的に圧縮\n",
    "def img(x):\n",
    "    y = Image.open(x)\n",
    "    y = y.convert(\"RGB\")\n",
    "    y = y.resize((50, 50))\n",
    "    y = np.asarray(y)\n",
    "    return y\n",
    "\n",
    "#画像の読み込み処理　インデックスを取得するためにenumerateを使用\n",
    "#folder名に一致するフォルダの中身を1次元配列かしながらXに格納\n",
    "#同時にYにはインデックス(今回はaplleフォルダが0,bananaフォルダが1)がXと1:1対応で格納される\n",
    "\n",
    "for index, name in enumerate(folder):\n",
    "    dir = \"./\" + name\n",
    "    files = glob.glob(dir + \"/*.png\")\n",
    "    for i, file in enumerate(files):\n",
    "        image = img(file)\n",
    "        X.append(image.flatten())\n",
    "        Y.append(index)\n",
    "\n",
    "X = np.array(X) / 255\n",
    "Y = np.array(Y)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "#Kerasで使うためにYの値をバイナリに変換\n",
    "Y = np_utils.to_categorical(Y, 2)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "#モデルの構築\n",
    "# とりあえず全結合のやつをつくってみる。一層目出力ノード数は適当\n",
    "model = Sequential([Dense(512, input_dim=7500), Activation(\"relu\"), Dense(2), Activation(\"softmax\")])\n",
    "#model = Sequential()\n",
    "#model.add(Dense(512, activation='relu', input_shape=(7500,)))\n",
    "#model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "#モデルのコンパイル\n",
    "#損失関数：交差エントロピー,最適化関数：sgb, 評価関数：正解率(acc)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "#学習。バッチサイズ:5, ログ出力:ブログレスバー,反復数:20,検証データの割合:0.3\n",
    "hist = model.fit(\n",
    "    X, Y,\n",
    "    batch_size=5,\n",
    "    verbose=1,\n",
    "    epochs=20,\n",
    "    validation_split=0.3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "banana\n"
    }
   ],
   "source": [
    "Xt = []\n",
    "testimg = img(\"ばなな.jpg\")\n",
    "\n",
    "\n",
    "Xt.append(testimg.flatten())\n",
    "Xt = np.array(Xt)/255\n",
    "\n",
    "#判定\n",
    "result = model.predict_classes(Xt)\n",
    "\n",
    "#判定結果\n",
    "if result == 0:\n",
    "    print(\"apple\")\n",
    "else:\n",
    "    print(\"banana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelの保存の重みを保存\n",
    "model.save_weights('applebanana.hdf5')\n",
    "\n",
    "#保存したモデルをロードする\n",
    "# model = load_model('applebanana.hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}