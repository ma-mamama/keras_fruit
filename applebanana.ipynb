{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599688931128",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nTrain on 153 samples, validate on 66 samples\nEpoch 1/20\n153/153 [==============================] - 7s 48ms/step - loss: 1.0924 - acc: 0.7320 - val_loss: 1.0462 - val_acc: 0.2576\nEpoch 2/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.3734 - acc: 0.8235 - val_loss: 1.7567 - val_acc: 0.1364\nEpoch 3/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.1910 - acc: 0.9412 - val_loss: 0.1353 - val_acc: 0.9848\nEpoch 4/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.2513 - acc: 0.9020 - val_loss: 0.2435 - val_acc: 0.9697\nEpoch 5/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.1187 - acc: 0.9739 - val_loss: 1.7779 - val_acc: 0.2727\nEpoch 6/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.1142 - acc: 0.9542 - val_loss: 0.1682 - val_acc: 0.9697\nEpoch 7/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0650 - acc: 0.9739 - val_loss: 2.0678 - val_acc: 0.2424\nEpoch 8/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.1190 - acc: 0.9673 - val_loss: 0.0492 - val_acc: 1.0000\nEpoch 9/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.1183 - acc: 0.9608 - val_loss: 0.5190 - val_acc: 0.7121\nEpoch 10/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0486 - acc: 0.9935 - val_loss: 0.0753 - val_acc: 1.0000\nEpoch 11/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.3469 - val_acc: 0.8788\nEpoch 12/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0320 - acc: 0.9804 - val_loss: 7.5751 - val_acc: 0.0606\nEpoch 13/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0674 - acc: 0.9935 - val_loss: 3.0031 - val_acc: 0.2121\nEpoch 14/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0292 - acc: 0.9935 - val_loss: 0.0591 - val_acc: 1.0000\nEpoch 15/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.1519 - val_acc: 0.9545\nEpoch 16/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9697\nEpoch 17/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1179 - val_acc: 0.9697\nEpoch 18/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9697\nEpoch 19/20\n153/153 [==============================] - 2s 14ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\nEpoch 20/20\n153/153 [==============================] - 2s 15ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 1.0000\n"
    }
   ],
   "source": [
    "folder = [\"apple\", \"banana\"]\n",
    "\n",
    "# 画像とラベルを格納するための配列を準備\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "#ファイルオープン～が配列生成までを関数化\n",
    "#画像サイズは50x50に強制的に圧縮\n",
    "def img(x):\n",
    "    y = Image.open(x)\n",
    "    y = y.convert(\"RGB\")\n",
    "    y = y.resize((50, 50))\n",
    "    y = np.asarray(y)\n",
    "    return y\n",
    "\n",
    "#画像の読み込み処理　インデックスを取得するためにenumerateを使用\n",
    "#folder名に一致するフォルダの中身を1次元配列かしながらXに格納\n",
    "#同時にYにはインデックス(今回はaplleフォルダが0,bananaフォルダが1)がXと1:1対応で格納される\n",
    "\n",
    "for index, name in enumerate(folder):\n",
    "    dir = \"./\" + name\n",
    "    files = glob.glob(dir + \"/*.png\")\n",
    "    for i, file in enumerate(files):\n",
    "        image = img(file)\n",
    "        X.append(image.flatten())\n",
    "        Y.append(index)\n",
    "\n",
    "X = np.array(X) / 255\n",
    "Y = np.array(Y)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "#Kerasで使うためにYの値をバイナリに変換\n",
    "Y = np_utils.to_categorical(Y, 2)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "#モデルの構築\n",
    "# とりあえず全結合のやつをつくってみる。一層目出力ノード数は適当\n",
    "model = Sequential([Dense(512, input_dim=7500), Activation(\"relu\"), Dense(2), Activation(\"softmax\")])\n",
    "#model = Sequential()\n",
    "#model.add(Dense(512, activation='relu', input_shape=(7500,)))\n",
    "#model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "#モデルのコンパイル\n",
    "#損失関数：交差エントロピー,最適化関数：sgb, 評価関数：正解率(acc)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "#学習。バッチサイズ:5, ログ出力:ブログレスバー,反復数:20,検証データの割合:0.3\n",
    "hist = model.fit(\n",
    "    X, Y,\n",
    "    batch_size=5,\n",
    "    verbose=1,\n",
    "    epochs=20,\n",
    "    validation_split=0.3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "banana\n"
    }
   ],
   "source": [
    "Xt = []\n",
    "testimg = img(\"ばなな.jpg\")\n",
    "\n",
    "\n",
    "Xt.append(testimg.flatten())\n",
    "Xt = np.array(Xt)/255\n",
    "\n",
    "#判定\n",
    "result = model.predict_classes(Xt)\n",
    "\n",
    "#判定結果\n",
    "if result == 0:\n",
    "    print(\"apple\")\n",
    "else:\n",
    "    print(\"banana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelの保存の重みを保存\n",
    "model.save('applebanana.hdf5')\n",
    "\n",
    "#保存したモデルをロードする\n",
    "#from keras.models import load_model\n",
    "# model = keras.models.load_model('applebanana.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}